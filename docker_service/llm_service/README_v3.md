# ğŸš€ RSS LLM Service v3.0 - Documentation

## ğŸ“‹ Vue d'ensemble

Le service `app_v3.py` est une refonte complÃ¨te qui implÃ©mente une **vraie utilisation de LLM** avec un systÃ¨me de fallback intelligent.

### ğŸ¯ Principales amÃ©liorations

1. **Classification LLM rÃ©elle** : Utilise DeBERTa pour une classification zero-shot
2. **Tags intelligents** : En anglais, sans doublons, contextuels
3. **Architecture hybride** : LLM quand disponible, rÃ¨gles en fallback
4. **RÃ©sumÃ©s dynamiques** : GÃ©nÃ©rÃ©s par DistilBART ou templates
5. **API unifiÃ©e** : Endpoint `/generate_metadata` qui fait tout

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Article RSS    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Classification  â”‚â”€â”€â”€â”€â–ºâ”‚ LLM DeBERTa  â”‚ (si disponible)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                      â”‚
         â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚              â”‚ Fallback Rules â”‚ (si LLM indisponible)
         â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tags + Alertes  â”‚ (GÃ©nÃ©ration intelligente)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    RÃ©sumÃ©       â”‚â”€â”€â”€â”€â–ºâ”‚ DistilBART   â”‚ (si disponible)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MÃ©tadonnÃ©es     â”‚ (JSON unifiÃ©)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¡ Endpoints API

### 1. `/generate_metadata` (Principal)

**MÃ©thode** : POST  
**Description** : Endpoint unifiÃ© qui retourne toutes les mÃ©tadonnÃ©es

**RequÃªte** :
```json
{
  "title": "Major Data Breach at TechCorp",
  "content": "A critical vulnerability has been exploited...",
  "source": "KrebsOnSecurity"
}
```

**RÃ©ponse** :
```json
{
  "domain": "cyber_investigations",
  "domain_label": "Cyber Investigations",
  "confidence": 87.5,
  "classification_method": "llm_zero_shot",
  "alert_level": "critical",
  "tags": ["cybercrime", "investigation", "data-breach", "urgent"],
  "obsidian_concepts": ["Cybercrime", "Digital Forensics", "Threat Intelligence"],
  "output_folder": "cyber-investigations",
  "processing_time": 0.342,
  "llm_used": true,
  "version": "3.0_hybrid"
}
```

### 2. `/classify` (Simple)

**Description** : Classification seule (utilise `/generate_metadata` en interne)

### 3. `/summarize` (RÃ©sumÃ©)

**RequÃªte** :
```json
{
  "title": "Article title",
  "content": "Article content...",
  "domain": "fraude_paiement"
}
```

**RÃ©ponse** :
```json
{
  "summary": "ğŸ’³ **Payment Security Alert**: Article title\n\nLLM-generated summary here...",
  "domain": "fraude_paiement",
  "processing_time": 1.23,
  "method": "llm",
  "version": "3.0"
}
```

### 4. Endpoints de monitoring

- `/health` : VÃ©rification rapide
- `/status` : Status dÃ©taillÃ© avec modÃ¨les chargÃ©s
- `/config/info` : Configuration actuelle
- `/reload_config` : Recharger la configuration

### 5. CompatibilitÃ© v2

- `/classify_v2` â†’ redirige vers `/generate_metadata`
- `/summarize_v2` â†’ redirige vers `/summarize`

## ğŸ”§ Configuration

### ModÃ¨les utilisÃ©s

1. **Classification** : `MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli`
   - Zero-shot classification
   - TrÃ¨s prÃ©cis pour la catÃ©gorisation

2. **RÃ©sumÃ©** : `sshleifer/distilbart-cnn-12-6`
   - ModÃ¨le lÃ©ger et rapide
   - RÃ©sumÃ©s de 50-150 mots

### Domaines supportÃ©s

```python
- fraude_investissement     # Investment fraud
- fraude_paiement          # Payment fraud
- fraude_president_cyber   # CEO fraud
- fraude_ecommerce         # E-commerce fraud
- supply_chain_cyber       # Supply chain attacks
- intelligence_economique  # Economic intelligence
- fraude_crypto           # Crypto fraud
- cyber_investigations    # General cybercrime
```

### Tags gÃ©nÃ©rÃ©s

- **Langue** : Anglais uniquement
- **Format** : lowercase-with-hyphens
- **Exemples** : `cybercrime`, `data-breach`, `urgent`, `high-confidence`
- **Maximum** : 6 tags par article

## ğŸš€ Utilisation

### Docker

Modifier le Dockerfile pour utiliser `app_v3.py` :

```dockerfile
# Dans llm_service/Dockerfile
CMD ["python", "app_v3.py"]
```

### Test local

```bash
# Installer les dÃ©pendances
pip install transformers torch flask

# Lancer le service
python app_v3.py
```

### Test des endpoints

```bash
# Test classification avec LLM
curl -X POST http://localhost:5000/generate_metadata \
  -H "Content-Type: application/json" \
  -d '{
    "title": "Ransomware Attack on Hospital",
    "content": "A major ransomware attack has encrypted...",
    "source": "SecurityWeek"
  }'

# VÃ©rifier le status
curl http://localhost:5000/status
```

## âš¡ Performance

| OpÃ©ration | Avec LLM | Sans LLM (fallback) |
|-----------|----------|---------------------|
| Classification | ~300ms | ~50ms |
| Tags | ~10ms | ~10ms |
| RÃ©sumÃ© | ~1.2s | ~50ms |
| Total `/generate_metadata` | ~1.5s | ~100ms |

## ğŸ”„ Mode Fallback

Si les modÃ¨les LLM ne peuvent pas Ãªtre chargÃ©s :

1. Classification â†’ Analyse par mots-clÃ©s
2. RÃ©sumÃ© â†’ Templates prÃ©dÃ©finis
3. Tags â†’ RÃ¨gles statiques
4. Performance â†’ 10x plus rapide mais moins prÃ©cis

## ğŸ› Troubleshooting

### Erreur de chargement des modÃ¨les

```
âŒ Erreur chargement modÃ¨les: [Errno 28] No space left on device
```

**Solution** : Les modÃ¨les nÃ©cessitent ~2GB d'espace. Nettoyer le disque ou utiliser le mode fallback.

### Timeout sur classification

**Solution** : RÃ©duire la taille du contenu envoyÃ© (limite Ã  1000 caractÃ¨res pour la classification).

### Tags en franÃ§ais apparaissent

**Solution** : VÃ©rifier que vous utilisez bien `app_v3.py` et non l'ancien `app.py`.

## ğŸ“ˆ Ã‰volutions futures

1. **Cache Redis** pour Ã©viter de reclassifier les mÃªmes articles
2. **Batch processing** pour traiter plusieurs articles d'un coup
3. **Fine-tuning** des modÃ¨les sur votre corpus spÃ©cifique
4. **API asynchrone** avec FastAPI pour meilleure performance

---

**Version** : 3.0  
**Date** : 26/05/2025  
**Auteur** : Pipeline RSS + LLM v3 Team
